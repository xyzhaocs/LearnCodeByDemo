{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c49d1e9c",
   "metadata": {},
   "source": [
    "[OpenAI Gym 经典控制环境介绍——CartPole（倒立摆）](https://zhuanlan.zhihu.com/p/570695189)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import envs\n",
    "d = envs.registry\n",
    "for k, v in d.items():\n",
    "    print(f\"{k} -> {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')      \n",
    "obs, _ = env.reset()\n",
    "\n",
    "# 初始化图像对象\n",
    "frame = env.render()\n",
    "plt.ion()  # 打开交互模式\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(frame)\n",
    "display.display(plt.gcf())\n",
    "\n",
    "for _ in range(500):\n",
    "    frame = env.render()\n",
    "    img.set_data(frame)  # 只更新图像数据，而不是重建\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    # plt.pause(0.001)  # 小延时允许刷新\n",
    "    action = env.action_space.sample()\n",
    "    print(f\"Action taken: {action} {env.observation_space}\")\n",
    "    obs, _, terminated, truncated, _ = env.step(action)\n",
    "    \n",
    "    # if terminated or truncated:\n",
    "        # print(f\"{terminated} {truncated}\")\n",
    "        # obs, _ = env.reset()\n",
    "\n",
    "plt.ioff()\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b0ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "\n",
    "# 定义策略网络\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# 定义价值网络\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=1):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# PPO 代理\n",
    "class PPOAgent:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, lr_policy=3e-4, lr_value=1e-3, gamma=0.99, lambd=0.95, epsilon=0.2):\n",
    "        self.policy = PolicyNetwork(input_dim, hidden_dim, output_dim)\n",
    "        self.value = ValueNetwork(input_dim, hidden_dim)\n",
    "    \n",
    "        self.optimizer_policy = optim.Adam(self.policy.parameters(), lr=lr_policy)\n",
    "        self.optimizer_value = optim.Adam(self.value.parameters(), lr=lr_value)\n",
    "    \n",
    "        self.gamma = gamma\n",
    "        self.lambd = lambd\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "        probs = self.policy(state)\n",
    "        dist = Categorical(probs)\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "        return action.item()#, log_prob\n",
    "\n",
    "    def compute_advantages(self, rewards, values, next_values, dones):\n",
    "        advantages = torch.zeros_like(rewards)\n",
    "        advantages[-1] = rewards[-1] + self.gamma * (1 - dones[-1]) * next_values[-1] - values[-1]\n",
    "    \n",
    "        for t in reversed(range(len(rewards)-1)):\n",
    "            delta = rewards[t] + self.gamma * (1 - dones[t]) * next_values[t] - values[t]\n",
    "            advantages[t] = delta + self.gamma * self.lambd * (1 - dones[t]) * advantages[t+1]\n",
    "    \n",
    "        returns = advantages + values\n",
    "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "    \n",
    "        return returns, advantages\n",
    "\n",
    "    def update(self, states, actions, log_probs_old, returns, advantages):\n",
    "        states = torch.tensor(states, dtype=torch.float)\n",
    "        actions = torch.tensor(actions, dtype=torch.long).unsqueeze(-1)\n",
    "        log_probs_old = torch.stack(log_probs_old).detach()\n",
    "        returns = torch.tensor(returns, dtype=torch.float).unsqueeze(-1)\n",
    "        advantages = torch.tensor(advantages, dtype=torch.float).unsqueeze(-1)\n",
    "    \n",
    "        for _ in range(10):  # 更新纪元数\n",
    "            log_probs = self.policy(states).gather(1, actions)\n",
    "            ratio = (log_probs / log_probs_old).exp()\n",
    "        \n",
    "            surr1 = ratio * advantages\n",
    "            surr2 = torch.clamp(ratio, 1 - self.epsilon, 1 + self.epsilon) * advantages\n",
    "        \n",
    "            loss_policy = -torch.min(surr1, surr2).mean()\n",
    "        \n",
    "            self.optimizer_policy.zero_grad()\n",
    "            loss_policy.backward()\n",
    "            self.optimizer_policy.step()\n",
    "        \n",
    "            values = self.value(states)\n",
    "            loss_value = nn.MSELoss()(values, returns)\n",
    "        \n",
    "            self.optimizer_value.zero_grad()\n",
    "            loss_value.backward()\n",
    "            self.optimizer_value.step()\n",
    "\n",
    "def train_ppo(env, agent, max_timesteps=500, batch_size=5000, n_updates=10):\n",
    "    state, _ = env.reset()  # 处理Gym v0.26+的返回值\n",
    "    episode_rewards = []\n",
    "    all_rewards = []\n",
    "    t = 0\n",
    "\n",
    "    while t < max_timesteps:\n",
    "        states, actions, rewards, next_states, dones, log_probs = [], [], [], [], [], []\n",
    "        batch_rewards = 0\n",
    "    \n",
    "        # 收集轨迹\n",
    "        for _ in range(batch_size):\n",
    "            action, log_prob = agent.get_action(state)\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)  # Gym v0.26+的返回参数\n",
    "            done = terminated or truncated  # 合并终止标志\n",
    "        \n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            next_states.append(next_state)\n",
    "            dones.append(done)\n",
    "            log_probs.append(log_prob)\n",
    "        \n",
    "            if done:\n",
    "                state, _ = env.reset()  # 重置环境并获取初始状态\n",
    "            else:\n",
    "                state = next_state\n",
    "            batch_rewards += reward\n",
    "            t += 1\n",
    "        \n",
    "            if done or t >= max_timesteps:\n",
    "                break\n",
    "    \n",
    "        episode_rewards.append(batch_rewards)\n",
    "        all_rewards.extend(rewards)\n",
    "    \n",
    "        # 计算回报和优势\n",
    "        states_tensor = torch.tensor(np.array(states), dtype=torch.float)\n",
    "        next_states_tensor = torch.tensor(np.array(next_states), dtype=torch.float)\n",
    "        dones_tensor = torch.tensor(dones, dtype=torch.float).unsqueeze(-1)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            values = agent.value(states_tensor).squeeze()\n",
    "            next_values = agent.value(next_states_tensor).squeeze()\n",
    "    \n",
    "        returns, advantages = agent.compute_advantages(torch.tensor(rewards, dtype=torch.float), \n",
    "                                                       values, next_values, dones_tensor.squeeze())\n",
    "    \n",
    "        # 更新策略和价值网络\n",
    "        agent.update(states, actions, log_probs, returns.numpy(), advantages.numpy())\n",
    "    \n",
    "        if t >= max_timesteps:\n",
    "            break\n",
    "\n",
    "    return all_rewards, episode_rewards\n",
    "\n",
    "# 初始化环境\n",
    "env = gym.make('CartPole-v1')\n",
    "input_dim = env.observation_space.shape[0]\n",
    "output_dim = env.action_space.n\n",
    "hidden_dim = 16\n",
    "\n",
    "# 初始化PPO代理\n",
    "agent = PPOAgent(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# 训练代理\n",
    "max_timesteps = 10000\n",
    "batch_size = 512\n",
    "all_rewards, episode_rewards = train_ppo(env, agent, max_timesteps, batch_size)\n",
    "\n",
    "# 打印每集的平均奖励\n",
    "print(\"每集的平均奖励:\", np.mean(episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63562593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')    \n",
    "state, _ = env.reset()  # 处理Gym v0.26+的返回值\n",
    "frame = env.render()\n",
    "plt.ion()  # 打开交互模式\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(frame)\n",
    "display.display(plt.gcf())\n",
    "\n",
    "for _ in range(512):\n",
    "    try:\n",
    "        frame = env.render()\n",
    "    except Exception as e:\n",
    "        print(f\"渲染错误: {e}\")\n",
    "        break\n",
    "    img.set_data(frame)  # 只更新图像数据，而不是重建\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    action = agent.get_action(state)\n",
    "    # if state[2] < 0:\n",
    "    #     action = 0\n",
    "    # else:\n",
    "    #     action = 1\n",
    "    next_state, reward, terminated, truncated, _ = env.step(action)  # Gym v0.26+的返回参数\n",
    "    state = next_state\n",
    "    if  truncated:\n",
    "        state, _ = env.reset()  # 重置环境并获取初始状态\n",
    "plt.ioff()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f10e1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Reward: 14.0, Epsilon: 0.99\n",
      "Episode 1, Reward: 23.0, Epsilon: 0.99\n",
      "Episode 2, Reward: 53.0, Epsilon: 0.99\n",
      "Episode 3, Reward: 19.0, Epsilon: 0.98\n",
      "Episode 4, Reward: 40.0, Epsilon: 0.98\n",
      "Episode 5, Reward: 38.0, Epsilon: 0.97\n",
      "Episode 6, Reward: 20.0, Epsilon: 0.97\n",
      "Episode 7, Reward: 15.0, Epsilon: 0.96\n",
      "Episode 8, Reward: 15.0, Epsilon: 0.96\n",
      "Episode 9, Reward: 34.0, Epsilon: 0.95\n",
      "Episode 10, Reward: 15.0, Epsilon: 0.95\n",
      "Episode 11, Reward: 36.0, Epsilon: 0.94\n",
      "Episode 12, Reward: 15.0, Epsilon: 0.94\n",
      "Episode 13, Reward: 17.0, Epsilon: 0.93\n",
      "Episode 14, Reward: 19.0, Epsilon: 0.93\n",
      "Episode 15, Reward: 49.0, Epsilon: 0.92\n",
      "Episode 16, Reward: 33.0, Epsilon: 0.92\n",
      "Episode 17, Reward: 18.0, Epsilon: 0.91\n",
      "Episode 18, Reward: 31.0, Epsilon: 0.91\n",
      "Episode 19, Reward: 12.0, Epsilon: 0.90\n",
      "Episode 20, Reward: 16.0, Epsilon: 0.90\n",
      "Episode 21, Reward: 17.0, Epsilon: 0.90\n",
      "Episode 22, Reward: 10.0, Epsilon: 0.89\n",
      "Episode 23, Reward: 14.0, Epsilon: 0.89\n",
      "Episode 24, Reward: 12.0, Epsilon: 0.88\n",
      "Episode 25, Reward: 42.0, Epsilon: 0.88\n",
      "Episode 26, Reward: 32.0, Epsilon: 0.87\n",
      "Episode 27, Reward: 73.0, Epsilon: 0.87\n",
      "Episode 28, Reward: 34.0, Epsilon: 0.86\n",
      "Episode 29, Reward: 24.0, Epsilon: 0.86\n",
      "Episode 30, Reward: 34.0, Epsilon: 0.86\n",
      "Episode 31, Reward: 57.0, Epsilon: 0.85\n",
      "Episode 32, Reward: 20.0, Epsilon: 0.85\n",
      "Episode 33, Reward: 73.0, Epsilon: 0.84\n",
      "Episode 34, Reward: 20.0, Epsilon: 0.84\n",
      "Episode 35, Reward: 17.0, Epsilon: 0.83\n",
      "Episode 36, Reward: 10.0, Epsilon: 0.83\n",
      "Episode 37, Reward: 30.0, Epsilon: 0.83\n",
      "Episode 38, Reward: 121.0, Epsilon: 0.82\n",
      "Episode 39, Reward: 32.0, Epsilon: 0.82\n",
      "Episode 40, Reward: 48.0, Epsilon: 0.81\n",
      "Episode 41, Reward: 24.0, Epsilon: 0.81\n",
      "Episode 42, Reward: 30.0, Epsilon: 0.81\n",
      "Episode 43, Reward: 35.0, Epsilon: 0.80\n",
      "Episode 44, Reward: 42.0, Epsilon: 0.80\n",
      "Episode 45, Reward: 19.0, Epsilon: 0.79\n",
      "Episode 46, Reward: 44.0, Epsilon: 0.79\n",
      "Episode 47, Reward: 54.0, Epsilon: 0.79\n",
      "Episode 48, Reward: 35.0, Epsilon: 0.78\n",
      "Episode 49, Reward: 20.0, Epsilon: 0.78\n",
      "Episode 50, Reward: 56.0, Epsilon: 0.77\n",
      "Episode 51, Reward: 20.0, Epsilon: 0.77\n",
      "Episode 52, Reward: 23.0, Epsilon: 0.77\n",
      "Episode 53, Reward: 85.0, Epsilon: 0.76\n",
      "Episode 54, Reward: 31.0, Epsilon: 0.76\n",
      "Episode 55, Reward: 55.0, Epsilon: 0.76\n",
      "Episode 56, Reward: 94.0, Epsilon: 0.75\n",
      "Episode 57, Reward: 41.0, Epsilon: 0.75\n",
      "Episode 58, Reward: 31.0, Epsilon: 0.74\n",
      "Episode 59, Reward: 26.0, Epsilon: 0.74\n",
      "Episode 60, Reward: 30.0, Epsilon: 0.74\n",
      "Episode 61, Reward: 12.0, Epsilon: 0.73\n",
      "Episode 62, Reward: 38.0, Epsilon: 0.73\n",
      "Episode 63, Reward: 10.0, Epsilon: 0.73\n",
      "Episode 64, Reward: 79.0, Epsilon: 0.72\n",
      "Episode 65, Reward: 104.0, Epsilon: 0.72\n",
      "Episode 66, Reward: 36.0, Epsilon: 0.71\n",
      "Episode 67, Reward: 20.0, Epsilon: 0.71\n",
      "Episode 68, Reward: 21.0, Epsilon: 0.71\n",
      "Episode 69, Reward: 29.0, Epsilon: 0.70\n",
      "Episode 70, Reward: 12.0, Epsilon: 0.70\n",
      "Episode 71, Reward: 21.0, Epsilon: 0.70\n",
      "Episode 72, Reward: 23.0, Epsilon: 0.69\n",
      "Episode 73, Reward: 29.0, Epsilon: 0.69\n",
      "Episode 74, Reward: 57.0, Epsilon: 0.69\n",
      "Episode 75, Reward: 25.0, Epsilon: 0.68\n",
      "Episode 76, Reward: 69.0, Epsilon: 0.68\n",
      "Episode 77, Reward: 20.0, Epsilon: 0.68\n",
      "Episode 78, Reward: 87.0, Epsilon: 0.67\n",
      "Episode 79, Reward: 45.0, Epsilon: 0.67\n",
      "Episode 80, Reward: 29.0, Epsilon: 0.67\n",
      "Episode 81, Reward: 32.0, Epsilon: 0.66\n",
      "Episode 82, Reward: 39.0, Epsilon: 0.66\n",
      "Episode 83, Reward: 28.0, Epsilon: 0.66\n",
      "Episode 84, Reward: 29.0, Epsilon: 0.65\n",
      "Episode 85, Reward: 25.0, Epsilon: 0.65\n",
      "Episode 86, Reward: 30.0, Epsilon: 0.65\n",
      "Episode 87, Reward: 18.0, Epsilon: 0.64\n",
      "Episode 88, Reward: 12.0, Epsilon: 0.64\n",
      "Episode 89, Reward: 29.0, Epsilon: 0.64\n",
      "Episode 90, Reward: 82.0, Epsilon: 0.63\n",
      "Episode 91, Reward: 33.0, Epsilon: 0.63\n",
      "Episode 92, Reward: 97.0, Epsilon: 0.63\n",
      "Episode 93, Reward: 19.0, Epsilon: 0.62\n",
      "Episode 94, Reward: 83.0, Epsilon: 0.62\n",
      "Episode 95, Reward: 46.0, Epsilon: 0.62\n",
      "Episode 96, Reward: 31.0, Epsilon: 0.61\n",
      "Episode 97, Reward: 140.0, Epsilon: 0.61\n",
      "Episode 98, Reward: 258.0, Epsilon: 0.61\n",
      "Episode 99, Reward: 69.0, Epsilon: 0.61\n",
      "Episode 100, Reward: 186.0, Epsilon: 0.60\n",
      "Episode 101, Reward: 83.0, Epsilon: 0.60\n",
      "Episode 102, Reward: 66.0, Epsilon: 0.60\n",
      "Episode 103, Reward: 116.0, Epsilon: 0.59\n",
      "Episode 104, Reward: 131.0, Epsilon: 0.59\n",
      "Episode 105, Reward: 48.0, Epsilon: 0.59\n",
      "Episode 106, Reward: 119.0, Epsilon: 0.58\n",
      "Episode 107, Reward: 121.0, Epsilon: 0.58\n",
      "Episode 108, Reward: 49.0, Epsilon: 0.58\n",
      "Episode 109, Reward: 39.0, Epsilon: 0.58\n",
      "Episode 110, Reward: 34.0, Epsilon: 0.57\n",
      "Episode 111, Reward: 67.0, Epsilon: 0.57\n",
      "Episode 112, Reward: 12.0, Epsilon: 0.57\n",
      "Episode 113, Reward: 20.0, Epsilon: 0.56\n",
      "Episode 114, Reward: 53.0, Epsilon: 0.56\n",
      "Episode 115, Reward: 37.0, Epsilon: 0.56\n",
      "Episode 116, Reward: 211.0, Epsilon: 0.56\n",
      "Episode 117, Reward: 20.0, Epsilon: 0.55\n",
      "Episode 118, Reward: 151.0, Epsilon: 0.55\n",
      "Episode 119, Reward: 75.0, Epsilon: 0.55\n",
      "Episode 120, Reward: 105.0, Epsilon: 0.55\n",
      "Episode 121, Reward: 16.0, Epsilon: 0.54\n",
      "Episode 122, Reward: 54.0, Epsilon: 0.54\n",
      "Episode 123, Reward: 72.0, Epsilon: 0.54\n",
      "Episode 124, Reward: 86.0, Epsilon: 0.53\n",
      "Episode 125, Reward: 129.0, Epsilon: 0.53\n",
      "Episode 126, Reward: 40.0, Epsilon: 0.53\n",
      "Episode 127, Reward: 35.0, Epsilon: 0.53\n",
      "Episode 128, Reward: 81.0, Epsilon: 0.52\n",
      "Episode 129, Reward: 139.0, Epsilon: 0.52\n",
      "Episode 130, Reward: 84.0, Epsilon: 0.52\n",
      "Episode 131, Reward: 82.0, Epsilon: 0.52\n",
      "Episode 132, Reward: 67.0, Epsilon: 0.51\n",
      "Episode 133, Reward: 143.0, Epsilon: 0.51\n",
      "Episode 134, Reward: 91.0, Epsilon: 0.51\n",
      "Episode 135, Reward: 102.0, Epsilon: 0.51\n",
      "Episode 136, Reward: 44.0, Epsilon: 0.50\n",
      "Episode 137, Reward: 100.0, Epsilon: 0.50\n",
      "Episode 138, Reward: 12.0, Epsilon: 0.50\n",
      "Episode 139, Reward: 60.0, Epsilon: 0.50\n",
      "Episode 140, Reward: 59.0, Epsilon: 0.49\n",
      "Episode 141, Reward: 20.0, Epsilon: 0.49\n",
      "Episode 142, Reward: 17.0, Epsilon: 0.49\n",
      "Episode 143, Reward: 83.0, Epsilon: 0.49\n",
      "Episode 144, Reward: 125.0, Epsilon: 0.48\n",
      "Episode 145, Reward: 47.0, Epsilon: 0.48\n",
      "Episode 146, Reward: 16.0, Epsilon: 0.48\n",
      "Episode 147, Reward: 68.0, Epsilon: 0.48\n",
      "Episode 148, Reward: 75.0, Epsilon: 0.47\n",
      "Episode 149, Reward: 167.0, Epsilon: 0.47\n",
      "Episode 150, Reward: 107.0, Epsilon: 0.47\n",
      "Episode 151, Reward: 145.0, Epsilon: 0.47\n",
      "Episode 152, Reward: 110.0, Epsilon: 0.46\n",
      "Episode 153, Reward: 127.0, Epsilon: 0.46\n",
      "Episode 154, Reward: 231.0, Epsilon: 0.46\n",
      "Episode 155, Reward: 150.0, Epsilon: 0.46\n",
      "Episode 156, Reward: 196.0, Epsilon: 0.46\n",
      "Episode 157, Reward: 103.0, Epsilon: 0.45\n",
      "Episode 158, Reward: 145.0, Epsilon: 0.45\n",
      "Episode 159, Reward: 165.0, Epsilon: 0.45\n",
      "Episode 160, Reward: 142.0, Epsilon: 0.45\n",
      "Episode 161, Reward: 161.0, Epsilon: 0.44\n",
      "Episode 162, Reward: 77.0, Epsilon: 0.44\n",
      "Episode 163, Reward: 138.0, Epsilon: 0.44\n",
      "Episode 164, Reward: 190.0, Epsilon: 0.44\n",
      "Episode 165, Reward: 147.0, Epsilon: 0.44\n",
      "Episode 166, Reward: 178.0, Epsilon: 0.43\n",
      "Episode 167, Reward: 101.0, Epsilon: 0.43\n",
      "Episode 168, Reward: 106.0, Epsilon: 0.43\n",
      "Episode 169, Reward: 117.0, Epsilon: 0.43\n",
      "Episode 170, Reward: 90.0, Epsilon: 0.42\n",
      "Episode 171, Reward: 170.0, Epsilon: 0.42\n",
      "Episode 172, Reward: 151.0, Epsilon: 0.42\n",
      "Episode 173, Reward: 97.0, Epsilon: 0.42\n",
      "Episode 174, Reward: 124.0, Epsilon: 0.42\n",
      "Episode 175, Reward: 45.0, Epsilon: 0.41\n",
      "Episode 176, Reward: 97.0, Epsilon: 0.41\n",
      "Episode 177, Reward: 26.0, Epsilon: 0.41\n",
      "Episode 178, Reward: 42.0, Epsilon: 0.41\n",
      "Episode 179, Reward: 34.0, Epsilon: 0.41\n",
      "Episode 180, Reward: 135.0, Epsilon: 0.40\n",
      "Episode 181, Reward: 41.0, Epsilon: 0.40\n",
      "Episode 182, Reward: 123.0, Epsilon: 0.40\n",
      "Episode 183, Reward: 41.0, Epsilon: 0.40\n",
      "Episode 184, Reward: 139.0, Epsilon: 0.40\n",
      "Episode 185, Reward: 137.0, Epsilon: 0.39\n",
      "Episode 186, Reward: 149.0, Epsilon: 0.39\n",
      "Episode 187, Reward: 117.0, Epsilon: 0.39\n",
      "Episode 188, Reward: 114.0, Epsilon: 0.39\n",
      "Episode 189, Reward: 78.0, Epsilon: 0.39\n",
      "Episode 190, Reward: 176.0, Epsilon: 0.38\n",
      "Episode 191, Reward: 168.0, Epsilon: 0.38\n",
      "Episode 192, Reward: 217.0, Epsilon: 0.38\n",
      "Episode 193, Reward: 127.0, Epsilon: 0.38\n",
      "Episode 194, Reward: 156.0, Epsilon: 0.38\n",
      "Episode 195, Reward: 165.0, Epsilon: 0.37\n",
      "Episode 196, Reward: 129.0, Epsilon: 0.37\n",
      "Episode 197, Reward: 20.0, Epsilon: 0.37\n",
      "Episode 198, Reward: 154.0, Epsilon: 0.37\n",
      "Episode 199, Reward: 66.0, Epsilon: 0.37\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, lr=1e-3, gamma=0.99, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995):\n",
    "        self.q_net = DQN(input_dim, hidden_dim, output_dim)\n",
    "        self.target_net = DQN(input_dim, hidden_dim, output_dim)\n",
    "        self.target_net.load_state_dict(self.q_net.state_dict())\n",
    "        self.optimizer = optim.Adam(self.q_net.parameters(), lr=lr)\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return random.randrange(self.output_dim)\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.q_net(state)\n",
    "        return q_values.argmax().item()\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def update(self, batch_size=64):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        states = torch.FloatTensor(states)\n",
    "        actions = torch.LongTensor(actions).unsqueeze(1)\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
    "        next_states = torch.FloatTensor(next_states)\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(1)\n",
    "\n",
    "        q_values = self.q_net(states).gather(1, actions)\n",
    "        next_q_values = self.target_net(next_states).max(1)[0].unsqueeze(1)\n",
    "        target = rewards + self.gamma * next_q_values * (1 - dones)\n",
    "\n",
    "        loss = nn.MSELoss()(q_values, target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def update_target(self):\n",
    "        self.target_net.load_state_dict(self.q_net.state_dict())\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "            \n",
    "# ...existing code...\n",
    "env = gym.make('CartPole-v1')\n",
    "input_dim = env.observation_space.shape[0]\n",
    "output_dim = env.action_space.n\n",
    "hidden_dim = 64\n",
    "agent = DQNAgent(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "episodes = 200\n",
    "batch_size = 64\n",
    "for ep in range(episodes):\n",
    "    state, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    for t in range(500):\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        agent.update(batch_size)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    agent.update_target()\n",
    "    print(f\"Episode {ep}, Reward: {total_reward}, Epsilon: {agent.epsilon:.2f}\")\n",
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
