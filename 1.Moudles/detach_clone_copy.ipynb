{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[【Pytorch】对比clone、detach以及copy_等张量复制操作](https://blog.csdn.net/guofei_fly/article/details/104486708)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. clone\n",
    "\n",
    "返回一个和源张量同shape、dtype和device的张量，与源张量`不共享数据内存`，但`提供梯度的回溯`。\n",
    "\n",
    "2. detach\n",
    "\n",
    "`detach`的机制则与`clone`完全不同，即返回一个和源张量同shape、dtype和device的张量，与源张量共享数据内存，但不提供梯度计算，即`requires_grad=False`，因此脱离计算图。\n",
    "\n",
    "3. `clone`和`detach`联合使用\n",
    "\n",
    "`clone`提供了非数据共享的梯度追溯功能，而`detach`又“舍弃”了梯度功能，因此`clone`和`detach`意味着着只做简单的数据复制，既不数据共享，也不对梯度共享，从此两个张量无关联。\n",
    "\n",
    "置于是先`clone`还是先`detach`，其返回值一样，一般采用`tensor.clone().detach()`。\n",
    "\n",
    "4. copy_\n",
    "\n",
    "copy_同样将源张量中的数据复制到目标张量（数据不共享），其`device`、`dtype`和`requires_grad`一般都保留目标张量的设定，仅仅进行数据复制，同时其支持`broadcast`操作。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
